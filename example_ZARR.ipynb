{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union, Optional, Callable, Dict, Generator\n",
    "\n",
    "import numpy as np\n",
    "import zarr\n",
    "from torch.utils.data import DataLoader, IterableDataset, get_worker_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = Path('.') / 'data' / 'test_ngff_image.zarr/0' \n",
    "patch_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zarr(file_path: Path) -> Union[zarr.core.Array, zarr.storage.DirectoryStore, zarr.hierarchy.Group]:\n",
    "    \"\"\"Reads a file and returns a pointer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : Path\n",
    "        pathlib.Path object containing a path to a file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Pointer to zarr storage\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError, OSError\n",
    "        if a file is not a valid tiff or damaged\n",
    "    ValueError\n",
    "        if data dimensions are not 2, 3 or 4\n",
    "    ValueError\n",
    "        if axes parameter from config is not consistent with data dimensions\n",
    "    \"\"\"\n",
    "    zarr_source = zarr.open(Path(file_path), mode=\"r\")\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(zarr_source, zarr.hierarchy.Group):\n",
    "        raise NotImplementedError(\"Group not supported yet\")\n",
    "\n",
    "    elif isinstance(zarr_source, zarr.storage.DirectoryStore):\n",
    "        raise NotImplementedError(\"DirectoryStore not supported yet\")\n",
    "\n",
    "    elif isinstance(zarr_source, zarr.core.Array):\n",
    "        # array should be of shape (S, (C), (Z), Y, X), iterating over S ?\n",
    "        # TODO what if array is not of that shape and/or chunks aren't defined and\n",
    "        if zarr_source.dtype == \"O\":\n",
    "            raise NotImplementedError(\"Object type not supported yet\")\n",
    "        else:\n",
    "            array = zarr_source\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported zarr object type {type(zarr_source)}\")\n",
    "\n",
    "    # TODO how to fix dimensions? Or just raise error?\n",
    "    # sanity check on dimensions\n",
    "    if len(array.shape) < 2 or len(array.shape) > 4:\n",
    "        raise ValueError(\n",
    "            f\"Incorrect data dimensions. Must be 2, 3 or 4 (got {array.shape}).\"\n",
    "        )\n",
    "    \"\"\"\n",
    "    return zarr_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches_random(arr: np.ndarray,\n",
    "                           patch_size: Union[List[int], Tuple[int]]\n",
    ") -> Generator[np.ndarray, None, None]:\n",
    "    \"\"\"\n",
    "    Generate patches from an array in a random manner.\n",
    "\n",
    "    The method calculates how many patches the image can be divided into and then\n",
    "    extracts an equal number of random patches.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Input image array.\n",
    "    patch_size : Tuple[int]\n",
    "        Patch sizes in each dimension.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    Generator[np.ndarray, None, None]\n",
    "        Generator of patches.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    n_patches_per_slice = np.ceil(np.prod(arr.shape[1:]) / np.prod(patch_size)).astype(\n",
    "        int\n",
    "    )\n",
    "    crop_coords = rng.integers(\n",
    "        0,\n",
    "        np.array(arr.shape[-len(patch_size):]) - np.array(patch_size),\n",
    "        size=(arr.shape[0], n_patches_per_slice, len(patch_size)),\n",
    "    )\n",
    "    for slice_idx in range(crop_coords.shape[0]):\n",
    "        sample = arr[slice_idx]\n",
    "        for patch_idx in range(crop_coords.shape[1]):\n",
    "            patch = sample[\n",
    "                    crop_coords[slice_idx, patch_idx, 0]: crop_coords[\n",
    "                                                              slice_idx, patch_idx, 0\n",
    "                                                          ]\n",
    "                                                          + patch_size[0],\n",
    "                    crop_coords[slice_idx, patch_idx, 1]: crop_coords[\n",
    "                                                              slice_idx, patch_idx, 1\n",
    "                                                          ]\n",
    "                                                          + patch_size[1],\n",
    "                    ]\n",
    "            yield patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZarrDataset(IterableDataset):\n",
    "    \"\"\"Dataset to extract patches from a zarr storage.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: Union[str, Path],\n",
    "            patch_extraction_method: str,\n",
    "            patch_size: Optional[Union[List[int], Tuple[int]]] = None,\n",
    "            num_patches: Optional[int] = None,\n",
    "            mean: Optional[float] = None,\n",
    "            std: Optional[float] = None,\n",
    "            patch_transform: Optional[Callable] = None,\n",
    "            patch_transform_params: Optional[Dict] = None,\n",
    "    ) -> None:\n",
    "        self.data_path = Path(data_path)\n",
    "        self.patch_extraction_method = patch_extraction_method\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.patch_transform = patch_transform\n",
    "        self.patch_transform_params = patch_transform_params\n",
    "\n",
    "        self.sample = read_zarr(self.data_path)\n",
    "\n",
    "    def _generate_patches(self):\n",
    "        patches = extract_patches_random(\n",
    "            self.sample,\n",
    "            self.patch_size,\n",
    "        )\n",
    "\n",
    "        for idx, patch in enumerate(patches):\n",
    "\n",
    "            if isinstance(patch, tuple):\n",
    "                patch = (patch, *patch[1:])\n",
    "            else:\n",
    "                patch = patch\n",
    "\n",
    "            if self.patch_transform is not None:\n",
    "                assert self.patch_transform_params is not None\n",
    "                patch = self.patch_transform(patch, **self.patch_transform_params)\n",
    "            if self.num_patches is not None and idx >= self.num_patches:\n",
    "                return\n",
    "            else:\n",
    "                yield patch\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterate over data source and yield single patch.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        np.ndarray\n",
    "        \"\"\"\n",
    "        worker_info = get_worker_info()\n",
    "        worker_id = worker_info.id if worker_info is not None else 0\n",
    "        num_workers = worker_info.num_workers if worker_info is not None else 1\n",
    "        yield from islice(self._generate_patches(), 0, None, num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ZarrDataset(\n",
    "    data_path=test_path,\n",
    "    patch_extraction_method='random',\n",
    "    patch_size=patch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset, batch_size=32, num_workers=4, prefetch_factor=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(dl):\n",
    "    print(i, batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('HDNn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "faf8b084d52efbff00ddf863c4fb0ca7a3b023f9f18590a5b65c31dc02d793e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
