{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://discuss.pytorch.org/t/dataloader-parallelization-synchronization-with-zarr-xarray-dask/176149\n",
    "# and https://gist.github.com/d-v-b/f460c7f673819d431cc958a04acbab8a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'array-8202acebf512c5e1b6f75dd67eefb970' (c: 2, z: 236,\n",
      "                                                            y: 275, x: 271)>\n",
      "dask.array<array, shape=(2, 236, 275, 271), dtype=uint16, chunksize=(2, 236, 275, 271), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * c        (c) float64 0.0 1.0\n",
      "  * z        (z) float64 0.0 0.5002 1.0 1.501 2.001 ... 116.0 116.5 117.0 117.5\n",
      "  * y        (y) float64 0.0 0.3604 0.7208 1.081 ... 97.67 98.03 98.39 98.75\n",
      "  * x        (x) float64 0.0 0.3604 0.7208 1.081 ... 96.23 96.59 96.95 97.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n<xarray.DataArray 'array-0a22e19c51aed195a0b364219bd996aa' (c: 2, z: 236,\\n                                                            y: 275, x: 271)>\\ndask.array<array, shape=(2, 236, 275, 271), dtype=uint16, chunksize=(2, 236, 275, 271), chunktype=numpy.ndarray>\\nCoordinates:\\n  * c        (c) float64 0.0 1.0\\n  * z        (z) float64 0.0 0.5002 1.0 1.501 2.001 ... 116.0 116.5 117.0 117.5\\n  * y        (y) float64 0.0 0.3604 0.7208 1.081 ... 97.67 98.03 98.39 98.75\\n  * x        (x) float64 0.0 0.3604 0.7208 1.081 ... 96.23 96.59 96.95 97.31\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xarray_ome_ngff.registry import get_adapters\n",
    "import zarr\n",
    "from typing import Union\n",
    "import dask.array as da\n",
    "from xarray import DataArray\n",
    "import os\n",
    "\n",
    "def infer_coords(group: zarr.Group, array: zarr.Array):\n",
    "    # these conditionals should be handled by a lower-level validation function\n",
    "    if 'multiscales' in group.attrs:\n",
    "        multiscales = group.attrs['multiscales']\n",
    "        if len(multiscales) > 0:\n",
    "            # note that technically the spec allows multiple references to the same zarr array\n",
    "            # because multiscales is a list\n",
    "            multiscale = multiscales[0]\n",
    "            ngff_version = multiscale.get(\"version\", None)\n",
    "            # get the appropriate Multiscale model depending on the version\n",
    "            if ngff_version == \"0.4\":\n",
    "                from pydantic_ome_ngff.v04 import Multiscale\n",
    "            elif ngff_version == \"0.5-dev\":\n",
    "                from pydantic_ome_ngff.latest import Multiscale\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Could not resolve the version of the multiscales metadata \",\n",
    "                    f\"found in the group metadata {dict(group.attrs)}\",\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(\"Multiscales attribute was empty.\")\n",
    "    else:\n",
    "        raise ValueError(\"Multiscales attribute not found.\")\n",
    "    xarray_adapters = get_adapters(ngff_version)\n",
    "    multiscales_meta = [Multiscale(**entry) for entry in multiscales]\n",
    "    transforms = []\n",
    "    axes = []\n",
    "    matched_multiscale, matched_dataset = None, None\n",
    "    # find the correct element in multiscales.datasets for this array\n",
    "    for multi in multiscales_meta:\n",
    "        for dataset in multi.datasets:\n",
    "            if dataset.path == array.basename:\n",
    "                matched_multiscale = multi\n",
    "                matched_dataset = dataset\n",
    "    if matched_dataset is None or matched_multiscale is None:\n",
    "        raise ValueError(\n",
    "            f\"\"\"\n",
    "        Could not find an entry referencing array {array.basename}\n",
    "        in the `multiscales` metadata of the parent group.\n",
    "        \"\"\"\n",
    "        )\n",
    "    else:\n",
    "        if matched_multiscale.coordinateTransformations is not None:\n",
    "            transforms.extend(matched_multiscale.coordinateTransformations)\n",
    "        transforms.extend(matched_dataset.coordinateTransformations)\n",
    "        axes.extend(matched_multiscale.axes)\n",
    "        coords = xarray_adapters.transforms_to_coords(axes, transforms, array.shape)\n",
    "        return coords\n",
    "\n",
    "\n",
    "def read_dataarray(group: zarr.Group, array: zarr.Array, use_dask: bool = True, **kwargs) -> DataArray:\n",
    "    coords = infer_coords(group, array)\n",
    "    if use_dask:\n",
    "        data = da.from_array(array, **kwargs)\n",
    "    else:\n",
    "        data = array\n",
    "    return DataArray(data, coords)\n",
    "\n",
    "def test_read_dataarray():\n",
    "    path = \"https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.4/idr0062A/6001240.zarr/\"\n",
    "    z_group = zarr.open(path, mode='r')\n",
    "    z_array = zarr.open(store=z_group.store, path = '0')\n",
    "    d_array = read_dataarray(z_group, z_array)\n",
    "    print(d_array)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     test_read_dataarray()\n",
    "\n",
    "\"\"\"\n",
    "<xarray.DataArray 'array-0a22e19c51aed195a0b364219bd996aa' (c: 2, z: 236,\n",
    "                                                            y: 275, x: 271)>\n",
    "dask.array<array, shape=(2, 236, 275, 271), dtype=uint16, chunksize=(2, 236, 275, 271), chunktype=numpy.ndarray>\n",
    "Coordinates:\n",
    "  * c        (c) float64 0.0 1.0\n",
    "  * z        (z) float64 0.0 0.5002 1.0 1.501 2.001 ... 116.0 116.5 117.0 117.5\n",
    "  * y        (y) float64 0.0 0.3604 0.7208 1.081 ... 97.67 98.03 98.39 98.75\n",
    "  * x        (x) float64 0.0 0.3604 0.7208 1.081 ... 96.23 96.59 96.95 97.31\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 92/313 [07:36<18:17,  4.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m### Define and test the Dataloader. This will stall for num_workers > 0 and prefetch_factor > 0.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m train_dataloader \u001b[39m=\u001b[39m DataLoader(train_data, batch_size\u001b[39m=\u001b[39m \u001b[39m32\u001b[39m, num_workers \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, prefetch_factor\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m X \u001b[39min\u001b[39;49;00m tqdm(train_dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mpass\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m# np.matmul(X,X) # do something\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     image_npy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, idx]\u001b[39m.\u001b[39;49mto_numpy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(image_npy, dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/clement/Documents/pytorch-zarr-loader/ome_xarray.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# return image\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/xarray/core/dataarray.py:778\u001b[0m, in \u001b[0;36mDataArray.to_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_numpy\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    768\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[39m    Coerces wrapped data to numpy and returns a numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m    DataArray.data\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariable\u001b[39m.\u001b[39;49mto_numpy()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/xarray/core/variable.py:1096\u001b[0m, in \u001b[0;36mVariable.to_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Coerces wrapped data to numpy and returns a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[39m# TODO an entrypoint so array libraries can choose coercion method?\u001b[39;00m\n\u001b[0;32m-> 1096\u001b[0m \u001b[39mreturn\u001b[39;00m to_numpy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/xarray/core/pycompat.py:116\u001b[0m, in \u001b[0;36mto_numpy\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39mchunks\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    115\u001b[0m     chunkmanager \u001b[39m=\u001b[39m get_chunked_array_type(data)\n\u001b[0;32m--> 116\u001b[0m     data, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m chunkmanager\u001b[39m.\u001b[39;49mcompute(data)\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, array_type(\u001b[39m\"\u001b[39m\u001b[39mcupy\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m    118\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mget()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/xarray/core/daskmanager.py:70\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mdata: DaskArray, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[np\u001b[39m.\u001b[39mndarray, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]:\n\u001b[1;32m     68\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray\u001b[39;00m \u001b[39mimport\u001b[39;00m compute\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m compute(\u001b[39m*\u001b[39;49mdata, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[39mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    328\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# around 25 minutes?\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "### Define the Dataset\n",
    "class XRData(Dataset):\n",
    "    def __init__(self, path):\n",
    "        # self.data = xr.open_zarr(path).to_array()\n",
    "\n",
    "        z_group = zarr.open(path, mode='r')\n",
    "        z_array = zarr.open(store=z_group.store, path = '0')\n",
    "        d_array = read_dataarray(z_group, z_array)\n",
    "        self.data = d_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_npy = self.data[..., idx].to_numpy()\n",
    "        image = torch.as_tensor(image_npy, dtype = torch.float)\n",
    "        # return image\n",
    "        return image\n",
    "\n",
    "data_path = 'data/huge.zarr/'\n",
    "train_data = XRData(data_path)\n",
    "print(train_data.__getitem__(0).shape)\n",
    "\n",
    "### Define and test the Dataloader. This will stall for num_workers > 0 and prefetch_factor > 0.\n",
    "train_dataloader = DataLoader(train_data, batch_size= 32, num_workers = 0, prefetch_factor=None)\n",
    "for X in tqdm(train_dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:08<00:00,  2.43it/s]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# around 2 minutes?\n",
    "\n",
    "### WORKAROUND\n",
    "class XRBatchData(Dataset):\n",
    "    def __init__(self, path, batch_size):\n",
    "\n",
    "        z_group = zarr.open(path, mode='r')\n",
    "        z_array = zarr.open(store=z_group.store, path = '0')\n",
    "        d_array = read_dataarray(z_group, z_array)\n",
    "        self.data = d_array\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(int(self.data.shape[-1])/self.batch_size)\n",
    "        # return int(len(self.data.global_id)/self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_npy = self.data[..., slice(idx*self.batch_size, (idx+1)*self.batch_size)].to_numpy()\n",
    "        # image_npy = self.data.isel(global_id = slice(idx*self.batch_size, (idx+1)*self.batch_size)).to_numpy()\n",
    "        image = torch.as_tensor(image_npy, dtype = torch.float)\n",
    "        return image\n",
    "\n",
    "batch_size = 32\n",
    "train_data = XRBatchData(data_path, batch_size)\n",
    "print(train_data.__getitem__(0).shape)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size= 1, num_workers = 0, prefetch_factor=None)\n",
    "for X in tqdm(train_dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 64/313 [07:05<27:34,  6.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:29\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m<timed exec>:18\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/zarr/core.py:826\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, selection)\u001b[0m\n\u001b[1;32m    824\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_orthogonal_selection(pure_selection, fields\u001b[39m=\u001b[39mfields)\n\u001b[1;32m    825\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_basic_selection(pure_selection, fields\u001b[39m=\u001b[39;49mfields)\n\u001b[1;32m    827\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/zarr/core.py:952\u001b[0m, in \u001b[0;36mArray.get_basic_selection\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_basic_selection_zd(selection\u001b[39m=\u001b[39mselection, out\u001b[39m=\u001b[39mout,\n\u001b[1;32m    950\u001b[0m                                         fields\u001b[39m=\u001b[39mfields)\n\u001b[1;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 952\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_basic_selection_nd(selection\u001b[39m=\u001b[39;49mselection, out\u001b[39m=\u001b[39;49mout,\n\u001b[1;32m    953\u001b[0m                                         fields\u001b[39m=\u001b[39;49mfields)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/zarr/core.py:995\u001b[0m, in \u001b[0;36mArray._get_basic_selection_nd\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_basic_selection_nd\u001b[39m(\u001b[39mself\u001b[39m, selection, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fields\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    990\u001b[0m     \u001b[39m# implementation of basic selection for array with at least one dimension\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \n\u001b[1;32m    992\u001b[0m     \u001b[39m# setup indexer\u001b[39;00m\n\u001b[1;32m    993\u001b[0m     indexer \u001b[39m=\u001b[39m BasicIndexer(selection, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 995\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_selection(indexer\u001b[39m=\u001b[39;49mindexer, out\u001b[39m=\u001b[39;49mout, fields\u001b[39m=\u001b[39;49mfields)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/zarr/core.py:1284\u001b[0m, in \u001b[0;36mArray._get_selection\u001b[0;34m(self, indexer, out, fields)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39mif\u001b[39;00m math\u001b[39m.\u001b[39mprod(out_shape) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1282\u001b[0m     \u001b[39m# allow storage to get multiple items at once\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mindexer)\n\u001b[0;32m-> 1284\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chunk_getitems(\n\u001b[1;32m   1285\u001b[0m         lchunk_coords, lchunk_selection, out, lout_selection,\n\u001b[1;32m   1286\u001b[0m         drop_axes\u001b[39m=\u001b[39;49mindexer\u001b[39m.\u001b[39;49mdrop_axes, fields\u001b[39m=\u001b[39;49mfields\n\u001b[1;32m   1287\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mshape:\n\u001b[1;32m   1289\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/zarr/core.py:2032\u001b[0m, in \u001b[0;36mArray._chunk_getitems\u001b[0;34m(self, lchunk_coords, lchunk_selection, out, lout_selection, drop_axes, fields)\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[39mfor\u001b[39;00m ckey, chunk_select, out_select \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(ckeys, lchunk_selection, lout_selection):\n\u001b[1;32m   2031\u001b[0m     \u001b[39mif\u001b[39;00m ckey \u001b[39min\u001b[39;00m cdatas:\n\u001b[0;32m-> 2032\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_chunk(\n\u001b[1;32m   2033\u001b[0m             out,\n\u001b[1;32m   2034\u001b[0m             cdatas[ckey],\n\u001b[1;32m   2035\u001b[0m             chunk_select,\n\u001b[1;32m   2036\u001b[0m             drop_axes,\n\u001b[1;32m   2037\u001b[0m             out_is_ndarray,\n\u001b[1;32m   2038\u001b[0m             fields,\n\u001b[1;32m   2039\u001b[0m             out_select,\n\u001b[1;32m   2040\u001b[0m             partial_read_decode\u001b[39m=\u001b[39;49mpartial_read_decode,\n\u001b[1;32m   2041\u001b[0m         )\n\u001b[1;32m   2042\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2043\u001b[0m         \u001b[39m# check exception type\u001b[39;00m\n\u001b[1;32m   2044\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/zarr/core.py:1946\u001b[0m, in \u001b[0;36mArray._process_chunk\u001b[0;34m(self, out, cdata, chunk_selection, drop_axes, out_is_ndarray, fields, out_selection, partial_read_decode)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[39mexcept\u001b[39;00m ArrayIndexError:\n\u001b[1;32m   1945\u001b[0m     cdata \u001b[39m=\u001b[39m cdata\u001b[39m.\u001b[39mread_full()\n\u001b[0;32m-> 1946\u001b[0m chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decode_chunk(cdata)\n\u001b[1;32m   1948\u001b[0m \u001b[39m# select data from chunk\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39mif\u001b[39;00m fields:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-zarr-loader/lib/python3.11/site-packages/zarr/core.py:2202\u001b[0m, in \u001b[0;36mArray._decode_chunk\u001b[0;34m(self, cdata, start, nitems, expected_shape)\u001b[0m\n\u001b[1;32m   2200\u001b[0m         chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compressor\u001b[39m.\u001b[39mdecode_partial(cdata, start, nitems)\n\u001b[1;32m   2201\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2202\u001b[0m         chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compressor\u001b[39m.\u001b[39;49mdecode(cdata)\n\u001b[1;32m   2203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2204\u001b[0m     chunk \u001b[39m=\u001b[39m cdata\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# around 35 minutes?\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "### Define the Dataset\n",
    "class ZarrRData(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.data = zarr.open(path, mode='r')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_npy = self.data[..., idx]\n",
    "        image = torch.as_tensor(image_npy, dtype = torch.float)\n",
    "        # return image\n",
    "        return image\n",
    "\n",
    "data_path = 'data/huge.zarr/0'\n",
    "train_data = ZarrRData(data_path)\n",
    "print(train_data.__getitem__(0).shape)\n",
    "\n",
    "### Define and test the Dataloader. This will stall for num_workers > 0 and prefetch_factor > 0.\n",
    "train_dataloader = DataLoader(train_data, batch_size= 32, num_workers = 0, prefetch_factor=None)\n",
    "for X in tqdm(train_dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-zarr-loader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
