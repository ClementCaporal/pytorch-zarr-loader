{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://discuss.pytorch.org/t/dataloader-parallelization-synchronization-with-zarr-xarray-dask/176149\n",
    "# and https://gist.github.com/d-v-b/f460c7f673819d431cc958a04acbab8a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'array-8202acebf512c5e1b6f75dd67eefb970' (c: 2, z: 236,\n",
      "                                                            y: 275, x: 271)>\n",
      "dask.array<array, shape=(2, 236, 275, 271), dtype=uint16, chunksize=(2, 236, 275, 271), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * c        (c) float64 0.0 1.0\n",
      "  * z        (z) float64 0.0 0.5002 1.0 1.501 2.001 ... 116.0 116.5 117.0 117.5\n",
      "  * y        (y) float64 0.0 0.3604 0.7208 1.081 ... 97.67 98.03 98.39 98.75\n",
      "  * x        (x) float64 0.0 0.3604 0.7208 1.081 ... 96.23 96.59 96.95 97.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n<xarray.DataArray 'array-0a22e19c51aed195a0b364219bd996aa' (c: 2, z: 236,\\n                                                            y: 275, x: 271)>\\ndask.array<array, shape=(2, 236, 275, 271), dtype=uint16, chunksize=(2, 236, 275, 271), chunktype=numpy.ndarray>\\nCoordinates:\\n  * c        (c) float64 0.0 1.0\\n  * z        (z) float64 0.0 0.5002 1.0 1.501 2.001 ... 116.0 116.5 117.0 117.5\\n  * y        (y) float64 0.0 0.3604 0.7208 1.081 ... 97.67 98.03 98.39 98.75\\n  * x        (x) float64 0.0 0.3604 0.7208 1.081 ... 96.23 96.59 96.95 97.31\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xarray_ome_ngff.registry import get_adapters\n",
    "import zarr\n",
    "from typing import Union\n",
    "import dask.array as da\n",
    "from xarray import DataArray\n",
    "import os\n",
    "\n",
    "def infer_coords(group: zarr.Group, array: zarr.Array):\n",
    "    # these conditionals should be handled by a lower-level validation function\n",
    "    if 'multiscales' in group.attrs:\n",
    "        multiscales = group.attrs['multiscales']\n",
    "        if len(multiscales) > 0:\n",
    "            # note that technically the spec allows multiple references to the same zarr array\n",
    "            # because multiscales is a list\n",
    "            multiscale = multiscales[0]\n",
    "            ngff_version = multiscale.get(\"version\", None)\n",
    "            # get the appropriate Multiscale model depending on the version\n",
    "            if ngff_version == \"0.4\":\n",
    "                from pydantic_ome_ngff.v04 import Multiscale\n",
    "            elif ngff_version == \"0.5-dev\":\n",
    "                from pydantic_ome_ngff.latest import Multiscale\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Could not resolve the version of the multiscales metadata \",\n",
    "                    f\"found in the group metadata {dict(group.attrs)}\",\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(\"Multiscales attribute was empty.\")\n",
    "    else:\n",
    "        raise ValueError(\"Multiscales attribute not found.\")\n",
    "    xarray_adapters = get_adapters(ngff_version)\n",
    "    multiscales_meta = [Multiscale(**entry) for entry in multiscales]\n",
    "    transforms = []\n",
    "    axes = []\n",
    "    matched_multiscale, matched_dataset = None, None\n",
    "    # find the correct element in multiscales.datasets for this array\n",
    "    for multi in multiscales_meta:\n",
    "        for dataset in multi.datasets:\n",
    "            if dataset.path == array.basename:\n",
    "                matched_multiscale = multi\n",
    "                matched_dataset = dataset\n",
    "    if matched_dataset is None or matched_multiscale is None:\n",
    "        raise ValueError(\n",
    "            f\"\"\"\n",
    "        Could not find an entry referencing array {array.basename}\n",
    "        in the `multiscales` metadata of the parent group.\n",
    "        \"\"\"\n",
    "        )\n",
    "    else:\n",
    "        if matched_multiscale.coordinateTransformations is not None:\n",
    "            transforms.extend(matched_multiscale.coordinateTransformations)\n",
    "        transforms.extend(matched_dataset.coordinateTransformations)\n",
    "        axes.extend(matched_multiscale.axes)\n",
    "        coords = xarray_adapters.transforms_to_coords(axes, transforms, array.shape)\n",
    "        return coords\n",
    "\n",
    "\n",
    "def read_dataarray(group: zarr.Group, array: zarr.Array, use_dask: bool = True, **kwargs) -> DataArray:\n",
    "    coords = infer_coords(group, array)\n",
    "    if use_dask:\n",
    "        data = da.from_array(array, **kwargs)\n",
    "    else:\n",
    "        data = array\n",
    "    return DataArray(data, coords)\n",
    "\n",
    "def test_read_dataarray():\n",
    "    path = \"https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.4/idr0062A/6001240.zarr/\"\n",
    "    z_group = zarr.open(path, mode='r')\n",
    "    z_array = zarr.open(store=z_group.store, path = '0')\n",
    "    d_array = read_dataarray(z_group, z_array)\n",
    "    print(d_array)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     test_read_dataarray()\n",
    "\n",
    "\"\"\"\n",
    "<xarray.DataArray 'array-0a22e19c51aed195a0b364219bd996aa' (c: 2, z: 236,\n",
    "                                                            y: 275, x: 271)>\n",
    "dask.array<array, shape=(2, 236, 275, 271), dtype=uint16, chunksize=(2, 236, 275, 271), chunktype=numpy.ndarray>\n",
    "Coordinates:\n",
    "  * c        (c) float64 0.0 1.0\n",
    "  * z        (z) float64 0.0 0.5002 1.0 1.501 2.001 ... 116.0 116.5 117.0 117.5\n",
    "  * y        (y) float64 0.0 0.3604 0.7208 1.081 ... 97.67 98.03 98.39 98.75\n",
    "  * x        (x) float64 0.0 0.3604 0.7208 1.081 ... 96.23 96.59 96.95 97.31\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 58/313 [04:48<21:16,  5.00s/it]"
     ]
    }
   ],
   "source": [
    "%%time # around 30 minutes?\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "### Define the Dataset\n",
    "class XRData(Dataset):\n",
    "    def __init__(self, path):\n",
    "        # self.data = xr.open_zarr(path).to_array()\n",
    "\n",
    "        z_group = zarr.open(path, mode='r')\n",
    "        z_array = zarr.open(store=z_group.store, path = '0')\n",
    "        d_array = read_dataarray(z_group, z_array)\n",
    "        self.data = d_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_npy = self.data[..., idx].to_numpy()\n",
    "        image = torch.as_tensor(image_npy, dtype = torch.float)\n",
    "        # return image\n",
    "        return image\n",
    "\n",
    "data_path = 'data/huge.zarr/'\n",
    "train_data = XRData(data_path)\n",
    "print(train_data.__getitem__(0).shape)\n",
    "\n",
    "### Define and test the Dataloader. This will stall for num_workers > 0 and prefetch_factor > 0.\n",
    "train_dataloader = DataLoader(train_data, batch_size= 32, num_workers = 0, prefetch_factor=None)\n",
    "for X in tqdm(train_dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:08<00:00,  2.43it/s]\n"
     ]
    }
   ],
   "source": [
    "%%time # around 2 minutes?\n",
    "\n",
    "### WORKAROUND\n",
    "class XRBatchData(Dataset):\n",
    "    def __init__(self, path, batch_size):\n",
    "\n",
    "        z_group = zarr.open(path, mode='r')\n",
    "        z_array = zarr.open(store=z_group.store, path = '0')\n",
    "        d_array = read_dataarray(z_group, z_array)\n",
    "        self.data = d_array\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(int(self.data.shape[-1])/self.batch_size)\n",
    "        # return int(len(self.data.global_id)/self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_npy = self.data[..., slice(idx*self.batch_size, (idx+1)*self.batch_size)].to_numpy()\n",
    "        # image_npy = self.data.isel(global_id = slice(idx*self.batch_size, (idx+1)*self.batch_size)).to_numpy()\n",
    "        image = torch.as_tensor(image_npy, dtype = torch.float)\n",
    "        return image\n",
    "\n",
    "batch_size = 32\n",
    "train_data = XRBatchData(data_path, batch_size)\n",
    "print(train_data.__getitem__(0).shape)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size= 1, num_workers = 0, prefetch_factor=None)\n",
    "for X in tqdm(train_dataloader):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-zarr-loader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
